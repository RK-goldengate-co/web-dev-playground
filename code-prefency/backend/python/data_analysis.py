#!/usr/bin/env python3
"""
Python Data Science vÃ  Machine Learning
á»¨ng dá»¥ng phÃ¢n tÃ­ch dá»¯ liá»‡u vá»›i pandas, numpy, scikit-learn, vÃ  matplotlib
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, confusion_matrix
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings('ignore')

# Set style cho matplotlib
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

class DataAnalyzer:
    """Lá»›p phÃ¢n tÃ­ch dá»¯ liá»‡u toÃ n diá»‡n"""

    def __init__(self, data_path=None):
        self.data = None
        self.processed_data = None
        self.models = {}
        self.scaler = StandardScaler()

        if data_path:
            self.load_data(data_path)

    def load_data(self, path, separator=','):
        """Táº£i dá»¯ liá»‡u tá»« file CSV"""
        try:
            self.data = pd.read_csv(path, sep=separator)
            print(f"âœ… ÄÃ£ táº£i dá»¯ liá»‡u tá»« {path}")
            print(f"ğŸ“Š KÃ­ch thÆ°á»›c: {self.data.shape}")
            print(f"ğŸ“‹ CÃ¡c cá»™t: {list(self.data.columns)}")
            return True
        except Exception as e:
            print(f"âŒ Lá»—i táº£i dá»¯ liá»‡u: {e}")
            return False

    def explore_data(self):
        """KhÃ¡m phÃ¡ dá»¯ liá»‡u cÆ¡ báº£n"""
        if self.data is None:
            print("âŒ ChÆ°a táº£i dá»¯ liá»‡u")
            return

        print("\nğŸ“Š THÃ”NG TIN Tá»”NG QUAN:")
        print("=" * 50)
        print(self.data.info())

        print("\nğŸ“ˆ THá»NG KÃŠ MÃ” Táº¢:")
        print("=" * 50)
        print(self.data.describe())

        print("\nğŸ” KIá»‚M TRA GIÃ TRá»Š NULL:")
        print("=" * 50)
        null_counts = self.data.isnull().sum()
        print(null_counts[null_counts > 0])

        print("\nğŸ“Š PHÃ‚N PHá»I Dá»® LIá»†U:")
        print("=" * 50)
        for col in self.data.columns:
            if self.data[col].dtype in ['int64', 'float64']:
                print(f"{col}: {self.data[col].skew():.2f} (skewness)")

    def clean_data(self):
        """LÃ m sáº¡ch dá»¯ liá»‡u"""
        if self.data is None:
            print("âŒ ChÆ°a táº£i dá»¯ liá»‡u")
            return

        self.processed_data = self.data.copy()

        # Xá»­ lÃ½ giÃ¡ trá»‹ null
        for col in self.processed_data.columns:
            if self.processed_data[col].isnull().sum() > 0:
                if self.processed_data[col].dtype in ['int64', 'float64']:
                    # Äiá»n giÃ¡ trá»‹ trung bÃ¬nh cho sá»‘
                    mean_val = self.processed_data[col].mean()
                    self.processed_data[col].fillna(mean_val, inplace=True)
                    print(f"âœ… Äiá»n giÃ¡ trá»‹ trung bÃ¬nh {mean_val:.2f} cho cá»™t {col}")
                else:
                    # Äiá»n giÃ¡ trá»‹ phá»• biáº¿n nháº¥t cho category
                    mode_val = self.processed_data[col].mode()[0]
                    self.processed_data[col].fillna(mode_val, inplace=True)
                    print(f"âœ… Äiá»n giÃ¡ trá»‹ phá»• biáº¿n '{mode_val}' cho cá»™t {col}")

        # Loáº¡i bá» dá»¯ liá»‡u trÃ¹ng láº·p
        duplicates = self.processed_data.duplicated().sum()
        if duplicates > 0:
            self.processed_data.drop_duplicates(inplace=True)
            print(f"âœ… Loáº¡i bá» {duplicates} báº£n ghi trÃ¹ng láº·p")

        print("âœ… LÃ m sáº¡ch dá»¯ liá»‡u hoÃ n thÃ nh!")

    def visualize_data(self):
        """Trá»±c quan hÃ³a dá»¯ liá»‡u"""
        if self.processed_data is None:
            print("âŒ ChÆ°a xá»­ lÃ½ dá»¯ liá»‡u")
            return

        # Thiáº¿t láº­p figure
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('PhÃ¢n tÃ­ch dá»¯ liá»‡u trá»±c quan', fontsize=16, fontweight='bold')

        # Histogram cho táº¥t cáº£ biáº¿n sá»‘
        numeric_cols = self.processed_data.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            self.processed_data[numeric_cols].hist(ax=axes[0, 0], bins=20, alpha=0.7)
            axes[0, 0].set_title('PhÃ¢n bá»‘ cÃ¡c biáº¿n sá»‘')
            axes[0, 0].tick_params(axis='x', rotation=45)

        # Box plot Ä‘á»ƒ phÃ¡t hiá»‡n outliers
        if len(numeric_cols) > 0:
            sns.boxplot(data=self.processed_data[numeric_cols], ax=axes[0, 1])
            axes[0, 1].set_title('Box plot - PhÃ¡t hiá»‡n outliers')
            axes[0, 1].tick_params(axis='x', rotation=45)

        # Correlation heatmap
        if len(numeric_cols) > 1:
            corr_matrix = self.processed_data[numeric_cols].corr()
            sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,
                       square=True, ax=axes[1, 0])
            axes[1, 0].set_title('Ma tráº­n tÆ°Æ¡ng quan')

        # Scatter plot cho má»‘i quan há»‡ giá»¯a 2 biáº¿n Ä‘áº§u tiÃªn
        if len(numeric_cols) >= 2:
            x_col, y_col = numeric_cols[0], numeric_cols[1]
            axes[1, 1].scatter(self.processed_data[x_col], self.processed_data[y_col], alpha=0.6)
            axes[1, 1].set_xlabel(x_col)
            axes[1, 1].set_ylabel(y_col)
            axes[1, 1].set_title(f'Má»‘i quan há»‡ {x_col} vs {y_col}')

        plt.tight_layout()
        plt.savefig('data_analysis_report.png', dpi=300, bbox_inches='tight')
        plt.show()

    def perform_clustering(self, n_clusters=3):
        """Thá»±c hiá»‡n phÃ¢n cá»¥m K-Means"""
        if self.processed_data is None:
            print("âŒ ChÆ°a xá»­ lÃ½ dá»¯ liá»‡u")
            return

        # Chuáº©n bá»‹ dá»¯ liá»‡u cho clustering
        numeric_data = self.processed_data.select_dtypes(include=[np.number])

        if numeric_data.empty:
            print("âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u sá»‘ Ä‘á»ƒ phÃ¢n cá»¥m")
            return

        # Chuáº©n hÃ³a dá»¯ liá»‡u
        scaled_data = self.scaler.fit_transform(numeric_data)

        # Thá»±c hiá»‡n K-Means
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        clusters = kmeans.fit_predict(scaled_data)

        # ThÃªm káº¿t quáº£ vÃ o dá»¯ liá»‡u
        self.processed_data['Cluster'] = clusters

        print(f"âœ… PhÃ¢n cá»¥m hoÃ n thÃ nh vá»›i {n_clusters} cá»¥m")
        print(f"ğŸ“Š KÃ­ch thÆ°á»›c cÃ¡c cá»¥m: {np.bincount(clusters)}")

        # Trá»±c quan hÃ³a káº¿t quáº£
        plt.figure(figsize=(10, 6))
        scatter = plt.scatter(scaled_data[:, 0], scaled_data[:, 1],
                            c=clusters, cmap='viridis', alpha=0.6)
        plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],
                   c='red', marker='X', s=200, label='Centers')
        plt.title('Káº¿t quáº£ phÃ¢n cá»¥m K-Means')
        plt.xlabel('Feature 1 (scaled)')
        plt.ylabel('Feature 2 (scaled)')
        plt.legend()
        plt.colorbar(scatter)
        plt.savefig('clustering_results.png', dpi=300, bbox_inches='tight')
        plt.show()

        return clusters

    def train_classification_model(self, target_column, test_size=0.2):
        """Huáº¥n luyá»‡n mÃ´ hÃ¬nh phÃ¢n loáº¡i"""
        if self.processed_data is None:
            print("âŒ ChÆ°a xá»­ lÃ½ dá»¯ liá»‡u")
            return

        if target_column not in self.processed_data.columns:
            print(f"âŒ KhÃ´ng tÃ¬m tháº¥y cá»™t má»¥c tiÃªu: {target_column}")
            return

        # Chuáº©n bá»‹ dá»¯ liá»‡u
        X = self.processed_data.drop(columns=[target_column])
        y = self.processed_data[target_column]

        # Encode categorical variables
        le = LabelEncoder()
        for col in X.columns:
            if X[col].dtype == 'object':
                X[col] = le.fit_transform(X[col])

        # Chia dá»¯ liá»‡u
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=y
        )

        # Chuáº©n hÃ³a dá»¯ liá»‡u
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)

        # Huáº¥n luyá»‡n mÃ´ hÃ¬nh
        model = RandomForestClassifier(n_estimators=100, random_state=42)
        model.fit(X_train_scaled, y_train)

        # Dá»± Ä‘oÃ¡n vÃ  Ä‘Ã¡nh giÃ¡
        y_pred = model.predict(X_test_scaled)
        accuracy = accuracy_score(y_test, y_pred)

        print("ğŸ“Š Káº¾T QUáº¢ MÃ” HÃŒNH PHÃ‚N LOáº I:")
        print("=" * 50)
        print(f"ğŸ¯ Äá»™ chÃ­nh xÃ¡c: {accuracy:.4f}")
        print(f"ğŸ“ˆ Classification Report:\n{classification_report(y_test, y_pred)}")

        # Confusion Matrix
        plt.figure(figsize=(8, 6))
        cm = confusion_matrix(y_test, y_pred)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=np.unique(y), yticklabels=np.unique(y))
        plt.title('Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
        plt.show()

        # Feature Importance
        if hasattr(model, 'feature_importances_'):
            plt.figure(figsize=(10, 6))
            feature_importance = pd.DataFrame({
                'feature': X.columns,
                'importance': model.feature_importances_
            }).sort_values('importance', ascending=True)

            plt.barh(feature_importance['feature'], feature_importance['importance'])
            plt.title('Feature Importance')
            plt.xlabel('Importance')
            plt.tight_layout()
            plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')
            plt.show()

        self.models['classification'] = model
        return model, accuracy

    def train_regression_model(self, target_column, test_size=0.2):
        """Huáº¥n luyá»‡n mÃ´ hÃ¬nh há»“i quy"""
        if self.processed_data is None:
            print("âŒ ChÆ°a xá»­ lÃ½ dá»¯ liá»‡u")
            return

        if target_column not in self.processed_data.columns:
            print(f"âŒ KhÃ´ng tÃ¬m tháº¥y cá»™t má»¥c tiÃªu: {target_column}")
            return

        # Chuáº©n bá»‹ dá»¯ liá»‡u
        X = self.processed_data.drop(columns=[target_column])
        y = self.processed_data[target_column]

        # Encode categorical variables
        le = LabelEncoder()
        for col in X.columns:
            if X[col].dtype == 'object':
                X[col] = le.fit_transform(X[col])

        # Chia dá»¯ liá»‡u
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42
        )

        # Chuáº©n hÃ³a dá»¯ liá»‡u
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)

        # Huáº¥n luyá»‡n mÃ´ hÃ¬nh
        model = RandomForestRegressor(n_estimators=100, random_state=42)
        model.fit(X_train_scaled, y_train)

        # Dá»± Ä‘oÃ¡n vÃ  Ä‘Ã¡nh giÃ¡
        y_pred = model.predict(X_test_scaled)
        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)

        print("ğŸ“Š Káº¾T QUáº¢ MÃ” HÃŒNH Há»’I QUY:")
        print("=" * 50)
        print(f"ğŸ“‰ Mean Squared Error: {mse:.4f}")
        print(f"ğŸ“ˆ Root Mean Squared Error: {rmse:.4f}")
        print(f"ğŸ¯ RÂ² Score: {model.score(X_test_scaled, y_test):.4f}")

        # Biá»ƒu Ä‘á»“ dá»± Ä‘oÃ¡n vs thá»±c táº¿
        plt.figure(figsize=(8, 6))
        plt.scatter(y_test, y_pred, alpha=0.6)
        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
        plt.xlabel('GiÃ¡ trá»‹ thá»±c táº¿')
        plt.ylabel('GiÃ¡ trá»‹ dá»± Ä‘oÃ¡n')
        plt.title('Dá»± Ä‘oÃ¡n vs Thá»±c táº¿')
        plt.savefig('regression_results.png', dpi=300, bbox_inches='tight')
        plt.show()

        # Residual plot
        residuals = y_test - y_pred
        plt.figure(figsize=(8, 6))
        plt.scatter(y_pred, residuals, alpha=0.6)
        plt.axhline(y=0, color='r', linestyle='--')
        plt.xlabel('GiÃ¡ trá»‹ dá»± Ä‘oÃ¡n')
        plt.ylabel('Residuals')
        plt.title('Residual Plot')
        plt.savefig('residual_plot.png', dpi=300, bbox_inches='tight')
        plt.show()

        self.models['regression'] = model
        return model, rmse

    def perform_pca(self, n_components=2):
        """Thá»±c hiá»‡n PCA Ä‘á»ƒ giáº£m chiá»u dá»¯ liá»‡u"""
        if self.processed_data is None:
            print("âŒ ChÆ°a xá»­ lÃ½ dá»¯ liá»‡u")
            return

        # Chuáº©n bá»‹ dá»¯ liá»‡u sá»‘
        numeric_data = self.processed_data.select_dtypes(include=[np.number])

        if numeric_data.shape[1] < 2:
            print("âŒ Cáº§n Ã­t nháº¥t 2 cá»™t sá»‘ Ä‘á»ƒ thá»±c hiá»‡n PCA")
            return

        # Loáº¡i bá» cá»™t má»¥c tiÃªu náº¿u cÃ³
        if 'Cluster' in numeric_data.columns:
            numeric_data = numeric_data.drop('Cluster', axis=1)

        # Chuáº©n hÃ³a dá»¯ liá»‡u
        scaled_data = self.scaler.fit_transform(numeric_data)

        # Thá»±c hiá»‡n PCA
        pca = PCA(n_components=n_components)
        pca_result = pca.fit_transform(scaled_data)

        # Táº¡o DataFrame vá»›i káº¿t quáº£ PCA
        pca_df = pd.DataFrame(
            pca_result,
            columns=[f'PC{i+1}' for i in range(n_components)]
        )

        print("ğŸ“Š Káº¾T QUáº¢ PCA:")
        print("=" * 30)
        print(f"ğŸ¯ Sá»‘ chiá»u gá»‘c: {scaled_data.shape[1]}")
        print(f"ğŸ¯ Sá»‘ chiá»u sau PCA: {n_components}")
        print(f"ğŸ“ˆ Giáº£i thÃ­ch phÆ°Æ¡ng sai: {pca.explained_variance_ratio_}")
        print(f"ğŸ“Š Tá»•ng phÆ°Æ¡ng sai giáº£i thÃ­ch: {pca.explained_variance_ratio_.sum():.4f}")

        # Trá»±c quan hÃ³a káº¿t quáº£ PCA
        plt.figure(figsize=(10, 8))
        scatter = plt.scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.6)

        # ThÃªm labels cho cÃ¡c Ä‘iá»ƒm náº¿u cÃ³ Ã­t dá»¯ liá»‡u
        if len(pca_result) <= 50:
            for i, (x, y) in enumerate(pca_result[:50]):
                plt.annotate(f'Point {i+1}', (x, y), xytext=(5, 5),
                           textcoords='offset points', fontsize=8)

        plt.xlabel(f'Principal Component 1 ({pca.explained_variance_ratio_[0]:.2%} variance)')
        plt.ylabel(f'Principal Component 2 ({pca.explained_variance_ratio_[1]:.2%} variance)')
        plt.title('PCA Results - 2D Visualization')
        plt.grid(True, alpha=0.3)
        plt.savefig('pca_results.png', dpi=300, bbox_inches='tight')
        plt.show()

        return pca_df, pca

    def generate_report(self, filename="data_analysis_report.html"):
        """Táº¡o bÃ¡o cÃ¡o phÃ¢n tÃ­ch dá»¯ liá»‡u"""
        if self.processed_data is None:
            print("âŒ ChÆ°a xá»­ lÃ½ dá»¯ liá»‡u")
            return

        html_content = f"""
        <!DOCTYPE html>
        <html lang="vi">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>BÃ¡o cÃ¡o phÃ¢n tÃ­ch dá»¯ liá»‡u</title>
            <style>
                body {{ font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; margin: 40px; line-height: 1.6; }}
                .header {{ text-align: center; color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 20px; }}
                .section {{ margin: 30px 0; }}
                .stats {{ background: #f8f9fa; padding: 20px; border-radius: 8px; margin: 10px 0; }}
                .highlight {{ background: #e8f5e8; padding: 15px; border-left: 4px solid #27ae60; }}
                img {{ max-width: 100%; height: auto; margin: 20px 0; }}
                table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
                th, td {{ padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }}
                th {{ background-color: #f2f2f2; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>ğŸ“Š BÃ¡o cÃ¡o phÃ¢n tÃ­ch dá»¯ liá»‡u</h1>
                <p>Táº¡o bá»Ÿi Python Data Analysis Tool</p>
                <p><strong>NgÃ y táº¡o:</strong> {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            </div>

            <div class="section">
                <h2>ğŸ“‹ ThÃ´ng tin dá»¯ liá»‡u</h2>
                <div class="stats">
                    <p><strong>KÃ­ch thÆ°á»›c dá»¯ liá»‡u:</strong> {self.processed_data.shape[0]} hÃ ng Ã— {self.processed_data.shape[1]} cá»™t</p>
                    <p><strong>Kiá»ƒu dá»¯ liá»‡u:</strong> {dict(self.processed_data.dtypes)}</p>
                </div>
            </div>

            <div class="section">
                <h2>ğŸ“ˆ Thá»‘ng kÃª mÃ´ táº£</h2>
                <div class="stats">
                    {self.processed_data.describe().to_html()}
                </div>
            </div>

            <div class="section">
                <h2>ğŸ” PhÃ¡t hiá»‡n váº¥n Ä‘á»</h2>
                <div class="highlight">
                    <p><strong>GiÃ¡ trá»‹ null:</strong> {self.processed_data.isnull().sum().sum()} giÃ¡ trá»‹ bá»‹ thiáº¿u</p>
                    <p><strong>Dá»¯ liá»‡u trÃ¹ng láº·p:</strong> {self.processed_data.duplicated().sum()} báº£n ghi trÃ¹ng láº·p</p>
                </div>
            </div>

            <div class="section">
                <h2>ğŸ“Š Káº¿t quáº£ phÃ¢n tÃ­ch</h2>
                <div class="highlight">
                    <p>BÃ¡o cÃ¡o phÃ¢n tÃ­ch chi tiáº¿t Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o cÃ¡c file hÃ¬nh áº£nh:</p>
                    <ul>
                        <li>data_analysis_report.png - Tá»•ng quan dá»¯ liá»‡u</li>
                        <li>clustering_results.png - Káº¿t quáº£ phÃ¢n cá»¥m</li>
                        <li>confusion_matrix.png - Ma tráº­n nháº§m láº«n</li>
                        <li>feature_importance.png - Táº§m quan trá»ng Ä‘áº·c trÆ°ng</li>
                        <li>regression_results.png - Káº¿t quáº£ há»“i quy</li>
                        <li>pca_results.png - Káº¿t quáº£ PCA</li>
                    </ul>
                </div>
            </div>

            <div class="section">
                <h2>ğŸ’¡ Khuyáº¿n nghá»‹</h2>
                <div class="highlight">
                    <ul>
                        <li>Kiá»ƒm tra vÃ  xá»­ lÃ½ outliers náº¿u cáº§n thiáº¿t</li>
                        <li>CÃ¢n nháº¯c loáº¡i bá» cÃ¡c Ä‘áº·c trÆ°ng cÃ³ tÆ°Æ¡ng quan cao</li>
                        <li>Thu tháº­p thÃªm dá»¯ liá»‡u náº¿u mÃ´ hÃ¬nh chÆ°a Ä‘á»§ chÃ­nh xÃ¡c</li>
                        <li>Thá»­ nghiá»‡m cÃ¡c mÃ´ hÃ¬nh khÃ¡c nhau Ä‘á»ƒ tÃ¬m mÃ´ hÃ¬nh tá»‘t nháº¥t</li>
                    </ul>
                </div>
            </div>
        </body>
        </html>
        """

        with open(filename, 'w', encoding='utf-8') as f:
            f.write(html_content)

        print(f"âœ… BÃ¡o cÃ¡o Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o {filename}")

    def export_processed_data(self, filename="processed_data.csv"):
        """Xuáº¥t dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½"""
        if self.processed_data is not None:
            self.processed_data.to_csv(filename, index=False)
            print(f"âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c xuáº¥t vÃ o {filename}")
        else:
            print("âŒ ChÆ°a cÃ³ dá»¯ liá»‡u Ä‘á»ƒ xuáº¥t")


# VÃ­ dá»¥ sá»­ dá»¥ng
if __name__ == "__main__":
    # Khá»Ÿi táº¡o analyzer
    analyzer = DataAnalyzer()

    # VÃ­ dá»¥ vá»›i dá»¯ liá»‡u máº«u (thay tháº¿ báº±ng Ä‘Æ°á»ng dáº«n thá»±c táº¿)
    print("ğŸš€ Báº®T Äáº¦U PHÃ‚N TÃCH Dá»® LIá»†U")
    print("=" * 60)

    # Táº£i dá»¯ liá»‡u máº«u (thay tháº¿ báº±ng dá»¯ liá»‡u thá»±c táº¿ cá»§a báº¡n)
    sample_data = pd.DataFrame({
        'age': np.random.normal(30, 10, 100),
        'income': np.random.normal(50000, 15000, 100),
        'score': np.random.normal(70, 15, 100),
        'category': np.random.choice(['A', 'B', 'C'], 100),
        'satisfaction': np.random.choice(['Low', 'Medium', 'High'], 100)
    })

    analyzer.data = sample_data
    analyzer.processed_data = sample_data.copy()

    # KhÃ¡m phÃ¡ dá»¯ liá»‡u
    analyzer.explore_data()

    # Trá»±c quan hÃ³a
    print("\nğŸ“Š ÄANG Táº O BIá»‚U Äá»’...")
    analyzer.visualize_data()

    # PhÃ¢n cá»¥m
    print("\nğŸ” ÄANG THá»°C HIá»†N PHÃ‚N Cá»¤M...")
    analyzer.perform_clustering(n_clusters=3)

    # Há»“i quy
    print("\nğŸ“ˆ ÄANG HUáº¤N LUYá»†N MÃ” HÃŒNH Há»’I QUY...")
    analyzer.train_regression_model('income')

    # PhÃ¢n loáº¡i
    print("\nğŸ¯ ÄANG HUáº¤N LUYá»†N MÃ” HÃŒNH PHÃ‚N LOáº I...")
    analyzer.train_classification_model('category')

    # PCA
    print("\nğŸ§® ÄANG THá»°C HIá»†N PCA...")
    analyzer.perform_pca(n_components=2)

    # Táº¡o bÃ¡o cÃ¡o
    print("\nğŸ“‹ ÄANG Táº O BÃO CÃO...")
    analyzer.generate_report()

    print("\nâœ… PHÃ‚N TÃCH HOÃ€N THÃ€NH!")
    print("ğŸ“ Kiá»ƒm tra cÃ¡c file Ä‘Ã£ táº¡o trong thÆ° má»¥c hiá»‡n táº¡i")
